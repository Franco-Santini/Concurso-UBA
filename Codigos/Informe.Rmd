---
title: "Informe concurso AsterionHouse"
author: "Gazze Sim√≥n, Moresi Manuel, Santini Franco"
date: "2025-08-12"
output: 
  html_document:
    theme: flatly
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      warning = FALSE,
                      message = FALSE, 
                      fig.align = "center")
```

# La Casa de Asteri√≥n: estimaci√≥n de demanda y optimizaci√≥n de precios de art√≠culos de venta minorista

```{r}
library(dplyr)
library(knitr)
library(kableExtra)
library(readr)
library(sparklyr)
library(ggplot2)
library(data.table)
library(arrow)
library(plotly)
library(lubridate)
library(usmap)

eci_stores <- read_csv("Datos/eci_stores.csv")

eci_product_groups <- read_csv("Datos/eci_product_groups.csv")

eci_product_master <- read_csv("Datos/eci_product_master.csv")

eci_stores_clusters <- read_csv("Datos/eci_stores_clusters.csv")
```

```{r}
#Datos

#df <- fread("Datos/eci_transactions.csv")  

#write_parquet(df, "eci_transactions.parquet")

#Configuraciones de spark
config <- spark_config()

# Establecemos la coneccion con spark
sc <- spark_connect(master = "local", config = config)

#ds <- open_dataset("eci_transactions.parquet")

#eci_transactions <- spark_read_parquet(sc, name = "eci_transacciones", path = "../eci_transactions.parquet")

#Para la base completa

# Copiar tabla de tiendas y productos a Spark

#eci_product_master <- rename(eci_product_master, SKU = sku, SUBGROUP = subgroup)
#eci_stores_tbl   <- copy_to(sc, eci_stores,        name = "eci_stores",        overwrite = TRUE)
#eci_products_tbl <- copy_to(sc, eci_product_master, name = "eci_product_master", overwrite = TRUE)

#Agrego los costos y precios base

#datos_tbl <- eci_transactions %>%
#  left_join(eci_products_tbl, by = c("SKU", "SUBGROUP"))

#Agrupo por el d√≠a, subproducto y tienda.

#print(colnames(datos_tbl))#Voy viendo que todas las variables esten

#datos_tbl <- datos_tbl %>%
#  mutate(QUANTITY = round(TOTAL_SALES / PRICE)) %>%
#  group_by(STORE_SUBGROUP_DATE_ID, category, group) %>%
#  summarise(
#    TOTAL_SALES_        = sum(TOTAL_SALES),
#    QUANTITY_           = sum(QUANTITY),
#    PRICE_              = sum(PRICE),
#    BASE_PRICE_         = sum(base_price),
#    INITIAL_TICKET_PRICE_ = sum(initial_ticket_price),
#    COSTOS_             = sum(costos)
#  ) %>%
#  ungroup() %>%
#  mutate(STORE_SUBGROUP_DATE_ID_2 = STORE_SUBGROUP_DATE_ID) %>%
#  tidyr::separate(STORE_SUBGROUP_DATE_ID_2, into = c("STORE_ID","SUBGROUP","DATE_ID"), sep = "_") #%>%
#  left_join(eci_stores_tbl, by = "STORE_ID")

#datos_tbl <- datos_tbl %>%
#  mutate(
#    DATE_ID = to_date(DATE_ID),  # convertir a fecha
#    DAY_OF_WEEK = date_format(DATE_ID, "E")  # "Mon", "Tue", ...
    # si quer√©s n√∫mero: DAY_OF_WEEK = date_format(DATE_ID, "u") # 1=lunes ... 7=domingo
#  )

  # Paso 1: convertir DATE_ID a Date
  

#print(colnames(datos_tbl))#Voy viendo que todas las variables esten

#Observo la cantidad de filas

#datos_tbl %>% tally()

#Obtengo el archivo .parquet de la base que usaremos para el objetivo 1

#spark_write_parquet(
#  datos_tbl,
#  path = "Datos/datos_final.parquet",
#  mode = "overwrite"  # o "append" si quer√©s agregar
#)

transactions_df <- read.csv("Datos/eci_transactions.csv", nrows = 6)

#Leo el archivo final y empiezo a hacer consultas

ds_final <- open_dataset("./Datos/datos_final_1.parquet")

print(colnames(ds_final))#Voy viendo que todas las variables esten

ds_final = ds_final %>%
  mutate(STORE_TYPE = if_else(is.na(STORE_TYPE), "Unknown", STORE_TYPE))
```

## Introducci√≥n

La empresa *La Casa de Asteri√≥n* es una cadena de negocios minoristas de art√≠culos para el hogar, la cual cuenta con 15 tiendas en distintas regiones de Estados Unidos. Recientemente dicha empresa ha detectado una reducci√≥n en las ganancias y buscan evaluar y mejorar su estrategia de precios para aumentar el rendimiento.

Teniendo en cuenta que la fijaci√≥n de precios es un factor clave para el rendimiento de cualquier negocio. Un precio demasiado alto puede reducir el volumen de ventas, mientras que uno demasiado bajo puede disminuir el margen de ganancia, incluso si la demanda aumenta. Encontrar el punto de equilibrio adecuado requiere no solo un an√°lisis detallado de las ventas y de la elasticidad de la demanda, sino tambi√©n la consideraci√≥n de factores externos como la competencia, la estacionalidad y los cambios en las preferencias de los consumidores.

Se busca comprender a fondo la relaci√≥n entre sus precios, la demanda y otros factores que puedan influir en su rendimiento, con el objetivo de implementar una estrategia de precios m√°s eficiente y orientada a resultados.

Se trabajar√° con informaci√≥n proveniente de las transacciones realizadas en 9 cadenas de negocios minoristas, entre las que se encuentra nuestro cliente *La casa de Asterion*, en un periodo de 3 a√±os, donde se podr√° obtener informaci√≥n de cada uno de los negocios y diferentes caracter√≠sticas relacionadas al producto que se vende.

**Aclaraci√≥n**: cuando se habla de transacci√≥n no refiere al evento completo de la compra, sino a la cantidad de productos iguales dentro de una compra.

## Objetivos

A lo largo de este trabajo tendremos en cuenta 2 objetivos principales:

1)  *Predecir la demanda diaria de la semana siguiente a la finalizaci√≥n de los datos disponibles*.

En base a la informaci√≥n prevista de las transacciones, se busca generar un modelo predictivo con el cual se pueda estimar de manera adecuada la demanda en pesos (\$) para cada uno de los d√≠as en la semana posterior al fin de los datos (desde el 1/1/2024 al 7/1/2024) de los distintos subproductos, en cada una de las tiendas minoristas.

2)  *Proponer soluciones para maximizar la ganancia*.

Como ya se mencion√≥ anteriormente, la cadena *Casa de Asteri√≥n* present√≥ una disminuci√≥n de las ganancias en el √∫ltimo tiempo. Por lo que se busca identificar, para cada producto, el precio √≥ptimo que maximice la ganancia, equilibrando el ingreso por unidad vendida con el volumen total de ventas y de esta manera poder revertir la situaci√≥n.

## Metodolog√≠a

### Datos

Fueron proporcionadas 6 bases de datos con distinta informaci√≥n relevante para la realizaci√≥n de este trabajo:

-   `eci_transaction`

Es la base de datos principal en este trabajo, en ella se encuentra informaci√≥n referida a las transacciones realizadas desde el 1 de enero de 2021 hasta el 31 de diciembre de 2023, en las 157 tiendas minoristas presentes en el estudio (pertenecientes a las 9 cadenas ya mencionadas). Las variables aqu√≠ presentes son:

<details>

<summary>üìÇ Variables</summary>

-   `TRANSACTION_ID` : id de la transacci√≥n

-   `DATE` : fecha de la transacci√≥n

-   `STORE_ID` : id de la tienda

-   `SKU`: n√∫mero de referencia CCCGGSSXXX donde C es la categor√≠a, G el grupo, S subgrupo y X es el n√∫mero secuencial del producto

-   `QUANTITY`: cantidad de productos que se vendieron en esa transacci√≥n.

-   `PRICE`: precio del producto.

-   `TOTAL_SALES` (`PRICE` x `QUANTITY`): dinero que recibe el local en una transacci√≥n.

-   `SUBGROUP`: subproducto.

-   `STORE_SUBGROUP_DATE_ID`: es el id del subproducto en cierta tienda y en cierta fecha.

</details>

<br>

-   `eci_stores`

Contiene informaci√≥n particular de cada una de las distintas tiendas minoristas,presentando informaci√≥n relacionada a la ubicaci√≥n y al tipo de tienda.En esta base de datos encontramos:

<details>

<summary>üìÇ Variables</summary>

-   `STORE_ID` : id de la tienda.

-   `BRAND` : cadena a la que pertenece la tienda.

-   `STORE_NAME` (generalmente formado por BRAND - CITY): nombre de la tienda.

-   `ADDRESS1` y `ADDRESS2`: informaci√≥n sobre la direcci√≥n de la tienda.

-   `CITY`: ciudad de la tienda.

-   `STATE` : estado de la tienda.

-   `ZIP` : c√≥digo postal de la tienda.

-   `OPENDATE` y `CLOSEDATE` : fecha de inicio y de cierre de la tienda.

-   `STORE_TYPE`: tipo de tienda.

-   `REGION`: regi√≥n de la tienda.

</details>

<br>

-   `eci_stores_cluster`

Este archivo contiene informaci√≥n de las tiendas minoristas, repitiendo las variables `STORE_ID`, `BRAND` y `STORE_NAME`, y agrega una variable que agrupa las tiendas por zona o regi√≥n:

<details>

<summary>üìÇ Variables</summary>

-   `STORE_ID` : id de la tienda.

-   `BRAND` : cadena a la que pertenece la tienda.

-   `STORE_NAME` (generalmente formado por BRAND - CITY): nombre de la tienda.

-   `CLUSTER`: zona o regi√≥n de la tienda.

</details>

<br>

-   `eci_product_master`

Contiene informaci√≥n m√°s espec√≠fica de los productos como el nombre, el precio inicial, el precio sugerido por el fabricante, los costos del mismo, entre otras:

<details>

<summary>üìÇ Variables</summary>

-   `SKU`: n√∫mero de referencia CCCGGSSXXX donde C es la categor√≠a, G el grupo, S subgrupo y X es el n√∫mero secuencial del producto

-   `PRODUCT_NAME`: nombre del producto.

-   `CATEGORY`: categor√≠a del producto.

-   `GROUP`: grupo del producto.

-   `SUBGROUP`: subproducto.

-   `BRAND`: cadena a la que pertenece la tienda.

-   `base_price`: precio al que el negocio puso en venta al producto en primera instancia.

-   `initial_ticket_price`: precio del producto sugerido por el fabricante.

-   `costos`: costo del producto.

</details>

<br>

-   `eci_product_groups`

Identifica productos que han estado en precio promocional por alg√∫n motivo, contiene las siguientes variables:

<details>

<summary>üìÇ Variables</summary>

-   `SKU`: n√∫mero de referencia CCCGGSSXXX donde C es la categor√≠a, G el grupo, S subgrupo y X es el n√∫mero secuencial del producto

-   `PRODUCT_NAME`: nombre del producto.

-   `price_group_id`: id de la promoci√≥n.

-   `price_group_name`: nombre completo de la promoci√≥n.

-   `group_type`: tipo de promoci√≥n.

</details>

<br>

-   `eci_customer_data`

Contiene informaci√≥n de 801923 clientes, identificando datos personales de los mismos e identificando a los que son socios de dichas cadenas:

<details>

<summary>üìÇ Variables</summary>

-   `client_id`: id del cliente.

-   `phone_number`: n√∫mero del cliente.

-   `email_address`: direcci√≥n de email del cliente.

-   `city`: ciudad de residencia del cliente.

-   `state`: estado de residencia del cliente.

-   `zip_code`: codigo postal del lugar de residencia del cliente.

-   `education_level`: nivel de educaci√≥n del cliente.

-   `occupation`: ocupaci√≥n del cliente.

-   `loyalty_member`: identifica si el cliente es socio o no de la cadena.

-   `loyalty_number`: n√∫mero de socio del cliente en caso de serlo.

-   `loyalty_points`: puntos de membres√≠a del cliente socio.

</details>

### Manejo de los datos

Antes de iniciar el an√°lisis, fue necesario realizar una inspecci√≥n exhaustiva de los datos. Este proceso permiti√≥ identificar aspectos relevantes vinculados al preprocesamiento, tales como la detecci√≥n de valores at√≠picos, la presencia de datos faltantes y otras cuestiones que requer√≠an tratamiento previo. Dichas cuestiones se enuncian a continuaci√≥n:

-   *Base de clientes (`eci_customer_data`)*

Al analizar las variables disponibles en esta base, qued√≥ evidenciado que no hay una variable que conecte la informaci√≥n aqu√≠ disponible con el resto de las bases. Es decir, se cuenta con la informaci√≥n de los clientes, pero no es posible identificar en que tienda compra cada uno, o que transacci√≥n realiza cada uno. Por este motivo no se utilizar√° esta informaci√≥n, al menos en este primer an√°lisis.

-   *Outliers*

Observando las variables cuantitativas de las bases de datos que se usar√°n inicialmente **no** se detectaron valores at√≠picos.

(Insertamos tabla con quartiles, minimo, media y maximo?)

-   *Valores faltantes*

Se realiz√≥ una inspecci√≥n por cada una de las variables de inter√©s y en la base de datos `eci_transaction` se encontraron valores faltantes en la variable `QUANTITY`, la cual como mencionamos anteriormente puede calcularse como `TOTAL_SALES`/`PRICE`, de esta manera se pudo reconstruir el dato e imputar todos los valores faltantes de dicha variable.

En la base de datos `eci_stores`, hay datos faltantes en las variables `ADDRESS2`, `CLOSEDATE` y `STORE_TYPE`. Para las variables `ADDRESS2` y `CLOSEDATE` puede que esto no sea un error en s√≠, sino que no esten los datos debido a que la tienda no tiene una segunda direcci√≥n o porque todav√≠a no cerr√≥ respectivamente. Para la variable `STORE_TYPE` encontramos 2 datos faltantes, en los locales QuickBuy - Columbia y MarketExpress Lakewood Uptown, los cuales fueron reemplazados por el valor *Unknown*, ya que no es posible saber de que tipo de tienda se trata.

-   *Datos del subproducto "Basketball"*

Al revisar la base de transacciones (`eci_transaction`) se identific√≥ que no existen registros asociados al subproducto "Basketball", a pesar de que este se encuentra incluido en la base de productos (`eci_product_master`) y forma parte de los subproductos a predecir en el primer objetivo. Una posible explicaci√≥n es que los SKU correspondientes a los subproductos de las categor√≠as "Basketball" y "Baseball" presentan coincidencias en su codificaci√≥n (por ejemplo, SPOTEBA001), lo que podr√≠a haber generado un error en el proceso de carga de datos y derivado en la ausencia de registros para "Basketball".

Una alternativa para solucionar este problema fue realizar el supuesto de que la demanda de ambos subproductos era similar, y en base a esto realizar las correspondientes predicciones. Como no se cuenta con la informaci√≥n de la demanda, ya que no podemos identificarlos entre las transacciones, podemos evidenciar las similitudes en las variables `base_price`, `initial_ticket_price` y `costos`:

```{r}
eci_product_master |> 
  filter(sku %in% c("SPOTEBA001", "SPOTEBA002", "SPOTEBA003", 
                    "SPOTEBA004", "SPOTEBA005", "SPOTEBA006", 
                    "SPOTEBA007", "SPOTEBA008")) |> 
  group_by(subgroup) |> 
  summarise(
    base_price_avg = mean(base_price, na.rm = TRUE),
    initial_ticket_price_avg = mean(initial_ticket_price, na.rm = TRUE),
    costos_avg = mean(costos, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  mutate(across(where(is.numeric), ~ round(.x, 2))) |> 
  kable(format = "html", caption = "Promedios de precios y costos por Subgrupo (Baseball vs Basketball)") |> 
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), 
                full_width = FALSE, position = "center")

```

Se observan similitudes tanto en los precios iniciales promedio, como en los costos promedios para los productos de Basketball y Baseball.

## Desarrollo

### Objetivo 1 - Estimaci√≥n de demanda

Para el desarrollo del Objetivo 1, se aplicar√°n t√©cnicas de Machine Learning con el prop√≥sito de entrenar los datos y estimar la demanda de los distintos subproductos. Asimismo, se llevar√° a cabo un procedimiento de estimaci√≥n de precios correspondiente a la semana de referencia para la generaci√≥n de pron√≥sticos. Estos valores estimados se incorporar√°n como variables explicativas en el modelo, con el objetivo de predecir de manera adecuada la demanda en la semana posterior al fin de los datos.

#### Preprocesamiento de los datos - Objetivo 1

Para la preparaci√≥n de los datos, se realizaron diversos procesos de depuraci√≥n y combinaci√≥n de las bases disponibles, con el fin de obtener un conjunto √∫nico que permitiera entrenar el modelo de predicci√≥n de la demanda.

En primer lugar, a partir de la base `eci_stores` se identificaron y excluyeron aquellas tiendas que hab√≠an cerrado antes de la semana del 1 al 7 de enero de 2024, ya que no tendr√≠a sentido estimar demanda para locales que ya no se encontraban operativos.

Posteriormente se combinaron las bases `eci_stores` y `eci_product_master` con la base `eci_transactions`. De esta forma, cada transacci√≥n no solo contiene informaci√≥n sobre la venta realizada, sino tambi√©n el nombre y la categor√≠a del producto, la tienda donde se comercializ√≥ y su regi√≥n, la franquicia a la que pertenece, entre otras caracter√≠sticas.

Sobre esta base consolidada, se generaron 3 nuevas variables temporales a partir de la columna `DATE`, extrayendo el d√≠a, mes y a√±o de cada transacci√≥n.

Finalmente, las transacciones se agruparon por d√≠a, por subproducto y por tienda (`STORE_SUBGROUP_DATE_ID`), con el prop√≥sito de entrenar los datos de esa manera y asi poder cumplir el objetivo de predecir la demanda desde el 1/1/2024 al 7/1/2024 de los distintos subproductos, en cada una de las tiendas minoristas. Tambi√©n, como dato adicional, esto hace que se reduzca el costo computacional que conlleva entrenar los datos, debido a la reduccion de filas en la base que este agrupamiento implica, pasando de trabajar con 19.004.759 de datos a una base final con 5.137.958 de datos.

En s√≠ntesis, el proceso de preparaci√≥n de datos permiti√≥ pasar de m√∫ltiples bases dispersas a un √∫nico conjunto de datos estructurado, listo para ser utilizado en el entrenamiento de los modelos predictivos y para el an√°lisis descriptivo que sigue a continuaci√≥n.

#### An√°lisis descriptivo - Objetivo 1

Al querer estimar la demanda (`TOTAL_SALES`) de manera adecuada, se plantea el an√°lisis descriptivo buscando evidenciar que variables entre las que se encuentran disponibles en nuestras bases pueden influir en el comportamiento de la variable respuesta mencionada.

Se cuenta con informaci√≥n de articulos pertenecientes a 73 subproductos distintos, e inicialmente se quiere evidenciar si hay diferencias en la demanda para los distintos subproductos.

```{r}
# Conteo por subgrupo
conteo_subgrupo <- ds_final %>%
  group_by(SUBGROUP) %>%
  summarise(
    total_ventas = sum(TOTAL_SALES_, na.rm = TRUE),
    cantidad = sum(QUANTITY_, na.rm = TRUE)
  ) %>%
  collect() %>%
  slice_max(order_by = total_ventas, n = 20)   # <- quedarte con los 20 m√°s grandes

# Gr√°fico de barras
plot_ly(
  data = conteo_subgrupo,
  x = ~total_ventas,
  y = ~reorder(SUBGROUP, total_ventas),
  type = "bar",
  orientation = "h",
  marker = list(color = "steelblue")
) %>%
  layout(
    title = "Top 20 Subgrupos por Demanda total (en $)",
    xaxis = list(title = "Demanda"),
    yaxis = list(title = "Subgrupo")
  )


#Porcentaje que acumulan los 9 primeros

# Vector con los 9 subgrupos
#top_subgrupos <- c("Headphones", "Speakers", "Wearables", "Desktops", 
#                   "Smartphones", "Home Audio", "Tablets", "Accesories", "Laptops")

# Calcular porcentaje
#porcentaje_top <- conteo_subgrupo %>% 
#  mutate(es_top = SUBGROUP %in% top_subgrupos) %>%
#  group_by(es_top) %>%
#  summarise(total_ventas_2 = sum(total_ventas, na.rm = TRUE)) %>%
#  mutate(pct = 100 * total_ventas_2 / sum(total_ventas_2))

#porcentaje_top
```

Claramente se observa que hay 9 subproductos que generaron mucha mayor demanda que el resto, estos productos son Headphones, Speakers, Wearables, Desktops, Smartphones, Home Audio, Tablets, Accesories y Laptops, acumulando un 42% de la demanda total.

Estos art√≠culos tienen caracter√≠sticas muy similares, todos ellos corresponden a productos electr√≥nicos vinculados principalmente a la inform√°tica, telecomunicaciones y entretenimiento audiovisual.

Cada uno de estos subgrupos (se diferencias 73 subgrupos distintos) se pueden agrupar en 23 grupos distintos, y a su vez estos grupos pertenecen a 8 categor√≠as distintas. A continuaci√≥n se presentan las distribuciones en relaci√≥n a la demanda total para estas variables.

```{r}
conteo_tree_plot <- ds_final %>%
  group_by(SUBGROUP,group) %>%
  summarise(
    total_ventas = sum(TOTAL_SALES_, na.rm = TRUE)
  ) %>%
  collect()

# Armar dataset con ra√≠z
conteo_tree_plot_root <- conteo_tree_plot %>%
  # Subgrupos: hijos de group
  mutate(
    label = SUBGROUP,
    parent = group,
    value = total_ventas
  ) %>%
  select(label, parent, value) %>%
  
  # Grupos: hijos de "Total"
  bind_rows(
    conteo_tree_plot %>%
      group_by(group) %>%
      summarise(value = sum(total_ventas), .groups = "drop") %>%
      mutate(label = group, parent = "Total") %>%
      select(label, parent, value)
  ) %>%
  
  # Ra√≠z: "Total"
  bind_rows(
    tibble(label = "Total", parent = "", value = sum(conteo_tree_plot$total_ventas))
  )

# Graficar
plot_ly(
  type = 'treemap',
  labels = conteo_tree_plot_root$label, 
  parents = conteo_tree_plot_root$parent, 
  values = conteo_tree_plot_root$value,
  branchvalues = "total",
  hoverinfo = "label+value+percent parent+percent root",
  textinfo = "label+value+percent parent+percent root"
)
```

Tal como se evidenciaba anteriormente, los productos relacionados a la electr√≥nica son los que presentan mayor demanda en \$, evidenciandose que los 9 productos que presentaban una mayor demanda que el resto se agrupan en los 3 "grupos": *Audio*, *Computing* y *Mobile*. Siendo adem√°s los 3 grupos que conforman la categor√≠a *Electronics*.

Otra variable que puede influir en la demanda de cada categor√≠a es la fecha en la que se produjo la transacci√≥n, para esto se mostrar√° la evoluci√≥n de la demanda a trav√©s de los meses en los 3 a√±os que abarca este estudio, y complementariamente mostraremos la demanda por d√≠a de la semana.

```{r}
# 1. Calcular ventas totales por subgrupo (para ordenar)
top_subgrupos <- ds_final %>%
  group_by(category) %>%
  summarise(total = sum(TOTAL_SALES_, na.rm = TRUE)) %>%
  arrange(desc(total))%>%
  collect() %>%
  pull(category)

# 2. Filtrar dataset solo con esos subgrupos
ventas_mensuales <- ds_final %>%
  mutate(month = floor_date(as.Date(DATE_ID), "month")) %>%
  filter(category %in% top_subgrupos) %>%
  group_by(month, category) %>%
  summarise(total_sales = sum(TOTAL_SALES_, na.rm = TRUE), .groups = "drop") %>%
  collect() %>%
  arrange(category, month)   


# 3. Gr√°fico interactivo con Plotly
p <- ventas_mensuales %>%
  plot_ly(
    x = ~month,
    y = ~total_sales,
    color = ~category,
    type = "scatter",
    mode = "lines"
  ) %>%
  layout(
    title = "Evoluci√≥n mensual de ventas - Categor√≠as",
    xaxis = list(title = "Mes"),
    yaxis = list(title = "Ventas Totales"))
p
```

Viendo la evoluci√≥n de la demanda por mes para las distintas categor√≠as, se podr√≠a detectar cierta estacionalidad, siendo los primeros meses del a√±o (generalmente desde enero hasta marzo/abril) los que menor demanda tienen, lo cual es de esperarse porque suelen ser meses de menor consumo. Es sabido que en los meses de noviembre y diciembre el consumo crece mucho por las fiestas (Thanksgiving, Black Friday, Navidad), posteriormente suele caer en los primeros meses del a√±o y suele volver a repuntar con el inicio de la primavera y algunas campa√±as de compras (por ejemplo, "back to school" m√°s adelante en el a√±o).

Se procede a analizar la demanda en las distintas regiones geogr√°ficas en las cuales pertenecen estas tiendas:

```{r}
ventas_estado <- ds_final %>%
group_by(STATE) %>%
summarise(total_sales = sum(TOTAL_SALES_),
cant_stores = n_distinct(STORE_ID),
.groups = "drop"
)
 
# unir las ventas con el mapa de estados
plot_data <- ventas_estado %>%
mutate(state = STATE,
ventas_tiendas = total_sales/cant_stores) %>%
collect()

options(scipen = 999)

plot_usmap(data = plot_data, values = "total_sales", regions = "states") +
scale_fill_continuous(
low = "white", high = "steelblue", name = "Demanda total por estado"
) +
theme(legend.position = "right")
```

Se observa que los estados con mayor demanda monetaria se encuentran en la zona de la costa este de Estados Unidos, concentrandose en los estados de Nueva York, Florida, Georgia y Carolina del Sur. Pero este analisis inicial no necesariamente brinda una evidencia con respecto a que dichos estados influyen en las ventas de las tiendas, debido a que hay distinta cantidad de tiendas en cada uno de estos. A continuaci√≥n para tratar este problema, se vuelve a realizar este gr√°fico pero calculando la demanda promedio de cada uno de estos estados:

```{r}
options(scipen = 999)

plot_usmap(data = plot_data, values = "ventas_tiendas", regions = "states") +
scale_fill_continuous(
low = "white", high = "steelblue", name = "Demanda promedio por estado"
) +
theme(legend.position = "right")
```

Al realizar esta modificaci√≥n, el panorama ya no es el mismo y se puede observar que los estados que mayor demanda promedio tienen se ubican en el suroeste y son los estados de Nuevo M√©xico y Arizona (contando con 2 y 5 tiendas respectivamente). Otra particularidad que no se evidenciaba en el otro gr√°fico, es que los estados con menor demanda promedio se encuentran todos en la regi√≥n noroeste del pa√≠s, lo que nos lleva a pensar que puede que esa sea una zona con menor consumo.

```{r}
# Conteo por subgrupo
conteo_store_type <- ds_final %>%
  group_by(STORE_TYPE) %>%
  summarise(total_ventas = sum(TOTAL_SALES_, na.rm = TRUE)) %>%
  collect()

conteo_tiendas = eci_stores %>%
  mutate(STORE_TYPE = if_else(is.na(STORE_TYPE), "Unknown", STORE_TYPE)) %>%
  group_by(STORE_TYPE) %>%
  summarise(cantidad_tiendas = n())

conteo_store_type = conteo_store_type %>%
  left_join(conteo_tiendas, by = "STORE_TYPE")


#Gr√°fico de barras

p1 <- plot_ly(
  conteo_store_type,
  y = ~total_ventas,
  x = ~reorder(STORE_TYPE, -total_ventas),
  type = "bar",
  name = "Demanda total ($)",
  marker = list(color = "steelblue")
) %>%
  layout(
    xaxis = list(title = "Demanda total ($)"),
    yaxis = list(title = "Tipo de Tienda")
  )

p2 <- plot_ly(
  conteo_store_type,
  y = ~cantidad_tiendas,
  x = ~reorder(STORE_TYPE, -total_ventas),
  type = "bar",
  name = "Cantidad Tiendas",
  marker = list(color = "maroon")
) %>%
  layout(
    xaxis = list(title = "Cantidad de Tiendas"),
    yaxis = list(title = "Tipo de Tienda")
  )

subplot(p1, p2, nrows = 2, shareY = TRUE, titleY = TRUE) %>%
  layout(title = "Demanda total ($) y Cantidad de Tiendas por Tipo",
    xaxis = list(
      tickfont = list(size = 10)
    ),
    xaxis2 = list(
      tickfont = list(size = 10)
    ),
    legend = list(
      font = list(
        size = 8.5
      )
    ))

```

Se puede apreciar con claridad que las tiendas de tipo *Street* y *Mall* son las que mayores demanda presentan, con la particularidad que existen las mismas cantidades de tiendas de estos tipos (44 cada uno), y sin embargo las de tipo *Street* tuvieron una demanda de \$48.194.937 mayor.

Al analizar los gr√°ficos, se observa de manera l√≥gica que una mayor cantidad de tiendas se asocia con un incremento en la demanda.

```{r}
# Conteo por brand
conteo_brand <- ds_final %>%
  group_by(BRAND) %>%
  summarise(total_ventas = sum(TOTAL_SALES_, na.rm = TRUE)) %>%
  collect()

conteo_franquicia = eci_stores %>%
  group_by(BRAND) %>%
  summarise(cantidad_tiendas = n())

conteo_brand = conteo_brand %>%
  left_join(conteo_franquicia, by = "BRAND")


#Gr√°fico de barras

p3 <- plot_ly(
  conteo_brand,
  y = ~total_ventas,
  x = ~reorder(BRAND, -total_ventas),
  type = "bar",
  name = "Demanda total ($)",
  marker = list(color = "steelblue")
) %>%
  layout(
    xaxis = list(title = "Demanda total ($)"),
    yaxis = list(title = "Marca")
  )

p4 <- plot_ly(
  conteo_brand,
  y = ~cantidad_tiendas,
  x = ~reorder(BRAND, -total_ventas),
  type = "bar",
  name = "Cantidad Tiendas por Marca",
  marker = list(color = "maroon")
) %>%
  layout(
    xaxis = list(title = "Cantidad de Tiendas"),
    yaxis = list(title = "Marca")
  )

subplot(p3, p4, nrows = 2, shareY = TRUE, titleY = TRUE) %>%
  layout(title = "Demanda total ($) y Cantidad de Tiendas por Marca",
    xaxis = list(
      tickfont = list(size = 7.5)
    ),
    xaxis2 = list(
      tickfont = list(size = 7.5)
    ),
    legend = list(
      font = list(
        size = 8.5
      )
    ))
```

Se evidencia que la marca *Essentials Plus* es la que mayor demanda presenta, siendo tambi√©n la marca con mayor cantidad de tiendas.

#### T√©cnicas estad√≠sticas - Objetivo 1

Antes de comenzar con el ajuste de modelos, se tiene en cuenta que la variable a predecir es cuantitativa, por lo que se opta por utilizar modelos de regresi√≥n. En primera instancia se consideraron varias alternativas, como regresi√≥n lineal, Random Forest, modelos de series de tiempo, entre otros. Sin embargo, dado el enfoque de predicci√≥n de cada uno de ellos, se decide trabajar con Random Forest para captar relaciones no lineales y predecir la demanda total de manera m√°s eficiente, las variables explicativas consideradas fueron: `PRICE`, `SUBGROUP`, `STORE_TYPE`, `REGION`, `STORE_ID`, `mes`, `dia`, `a√±o`, `category`, `group` y `BRAND`.

Dado que Random Forest posee m√∫ltiples hiperpar√°metros, se lleva a cabo un proceso de optimizaci√≥n de los mismos. Para ello, se divide el conjunto de datos en 85% entrenamiento y 15% testeo. Dentro del 85% destinado a entrenamiento se realiza un proceso de validaci√≥n cruzada con 4 "folds" con el objetivo de identificar aquellos hiperpar√°metros que maximizan el $R^2$. Luego, con el 15% restante se prueba el modelo ajustado con los hiperpar√°metros √≥ptimos, verificando que el $R^2$ obtenido sea consistente con el alcanzado en el proceso de validaci√≥n. Finalmente, se reentrenar√° el modelo con los hiperpar√°metros √≥ptimos con la totalidad de los datos para posteriormente realizar la predicci√≥n de la demanda total.

![](optimizaci√≥ndehiperpar√°metros.png)

##### Random Forest + modelos ARIMA para la determinaci√≥n del precio semanal

En esta opci√≥n se plantea usar Random Forest para la predicci√≥n de la demanda total, y modelos de series de tiempo para la determinaci√≥n del precio en el conjunto de datos a predecir. La justificaci√≥n del uso de modelos de series temporales es porque √©stos captan los patrones estacionales de los datos y usar esa informaci√≥n es una buena estrategia para determinar el precio.

Se utilizaron 10950 modelos SARIMA que resultan de las combinaciones de las 150 tiendas y 73 subgrupos a predecir, las restantes 150 combinaciones son para las tiendas que venden subgrupos de productos de ‚ÄúBasketball‚Äù pero √©stas son imputadas al precio que se venden los productos del ‚ÄúBaseball‚Äù, para modelar patrones semanales dado que se intuye que los precios en una semana de cada subgrupo de productos en cada tienda tienden a ser los mismos.

Para la determinaci√≥n del precio en cada subgrupo de productos y en cada tienda, se utiliz√≥ el precio mediano de cada producto vendido en ese subgrupo de productos, en cada tienda y semana del a√±o, la utilizaci√≥n de la mediana se debe a que es m√°s robusta ante datos extremos, con esto nos referimos a que va a ser un estimador m√°s consistente del precio.

Dado que hab√≠a tiendas que no vend√≠an todos los subgrupos de productos todas las semanas, en esas se uso un precio interpolado entre la semana previa y la semana siguiente dando a entender que el precio se comport√≥ de forma estable, luego, si el precio al inicio de la semana era faltante se usaba el precio de la semana siguiente y si el precio de la √∫ltima semana era faltante se usaba el precio de la semana anterior (estos dos √∫ltimos casos son para inicio y final del per√≠odo en estudio respectivamente).

##### Random Forest + modelos ARIMA para la determinaci√≥n del precio diario

En esta opci√≥n se trabaja de forma similar, se vuelve a utilizar Random Forest para la predicci√≥n de la demanda total, y modelos de series de tiempo para la determinaci√≥n del precio en el conjunto de datos a predecir.

La diferencia entre esta opci√≥n y la otra es la forma de como se modelan las series temporales, en este caso, se utilizaron 10950 modelos SARIMA que resultan de las combinaciones de las 150 tiendas y 73 subgrupos a predecir, las restantes 150 combinaciones son para las tiendas que venden subgrupos de productos de ‚ÄúBasketball‚Äù pero √©stas son imputadas al precio que se venden los productos del ‚ÄúBaseball‚Äù, para modelar patrones diarios e intentar captar la mayor cantidad de informaci√≥n posible para el pron√≥stico del precio.

Nuevamente, para la determinaci√≥n del precio en cada subgrupo de productos y en cada tienda, se utiliz√≥ el precio mediano de cada producto vendido en ese subgrupo de productos, en cada tienda y d√≠a del a√±o. Dado que hab√≠a tiendas que no vend√≠an todos los subgrupos de productos todas los d√≠as, se us√≥ un precio interpolado entre el/los d√≠a/as previo/os y el/los d√≠a/as siguiente/es dando a entender que el precio se comport√≥ de forma estable, luego, si el precio al primer d√≠a del a√±o era faltante se usaba el precio de el/los d√≠a/as siguiente/es y si el precio al √∫ltimo d√≠a del a√±o era faltante se usaba el precio de √©l/las semana/as anterior/es (estos dos √∫ltimos casos son para inicio y final del per√≠odo en estudio respectivamente).

#### Resultados - Objetivo 1

......

### Objetivo 2 - Optimizaci√≥n de precios

Como se mencion√≥ previamente, la Casa de Asteri√≥n necesita mejorar su estrategia de precios, ya que se ha observado una disminuci√≥n en las ganancias y desea entender c√≥mo ajustar sus precios para optimizar la demanda y el margen de ganancias de sus productos.

Luego de crear un modelo predictivo de la cantidad de ventas, se deber√°n identificar los precios √≥ptimos para cada producto que maximicen la ganancia. Esto implica encontrar el equilibrio adecuado entre el precio y la demanda para asegurar que la empresa obtenga el mayor rendimiento posible.

...... 

#### Preprocesamiento de los datos - Objetivo 2

A partir de la base creada luego de combinar las bases `eci_transactions`, `eci_stores` y `eci_product_master`, en donde se muestran todas las transacciones con sus diferentes caracter√≠sticas, se procede a calcular las ganancias para cada transacci√≥n, las cuales ser√°n de vital importancia para responder al objetivo en cuesti√≥n. El calculo se realiza de la siguiente manera:

`GANANCIAS` = `TOTAL_SALES` - `QUANTITY` x `costos`

A continuaci√≥n, se realizar√° un an√°lisis descriptivo con la base armada para este objetivo.

#### An√°lisis descriptivo - Objetivo 2

```{r}
df <- fread("Datos/eci_transactions.csv")  

write_parquet(df, "eci_transactions.parquet")

eci_transactions <- spark_read_parquet(sc, name = "eci_transacciones", path = "./eci_transactions.parquet")

#Para la base completa

# Copiar tabla de tiendas y productos a Spark

eci_product_master <- rename(eci_product_master, SKU = sku, SUBGROUP = subgroup)
eci_stores_tbl   <- copy_to(sc, eci_stores,        name = "eci_stores",        overwrite = TRUE)
eci_products_tbl <- copy_to(sc, eci_product_master, name = "eci_product_master", overwrite = TRUE)

#Agrego los costos y precios base

datos_tbl_2 <- eci_transactions %>%
 left_join(eci_products_tbl, by = c("SKU", "SUBGROUP")) %>%
 left_join(eci_stores_tbl, by = "STORE_ID") %>%
  select(-BRAND) %>%
  mutate(
   DATE = to_date(DATE),  # convertir a fecha
   DAY_OF_WEEK = date_format(DATE, "E"),
   STORE_TYPE = if_else(is.na(STORE_TYPE), "Unknown", STORE_TYPE)) # "Mon", "Tue", ... si quer√©s n√∫mero: DAY_OF_WEEK = date_format(DATE_ID, "u") # 1=lunes ... 7=domingo

print(colnames(datos_tbl_2))#Voy viendo que todas las variables esten


SKU_ganancia <- datos_tbl_2 %>%
  mutate(GANANCIAS = TOTAL_SALES - QUANTITY*costos) %>%
  group_by(product_name) %>%
  summarise(GANANCIAS_ = sum(GANANCIAS)) %>% 
  collect() %>%
  slice_max(order_by = GANANCIAS_, n = 20) 
  

plot_ly(
  SKU_ganancia,
  y = ~GANANCIAS_,
  x = ~reorder(product_name, -GANANCIAS_),
  type = "bar",
  name = "Ganancias",
  marker = list(color = "steelblue")
) %>%
  layout(
    title = "Ganancias totales ($) por producto",
    xaxis = list(title = "Producto",
      tickfont = list(size = 9)),
    yaxis = list(title = "Ganancias")
  ) 

```

```{r}
SKU_ganancia_prom <- datos_tbl_2 %>%
  mutate(GANANCIAS = TOTAL_SALES - QUANTITY*costos) %>%
  group_by(product_name) %>%
  summarise(GANANCIAS_ = sum(GANANCIAS),
            cantidad_prod = sum(QUANTITY)) %>% 
  mutate(prom_ganancias = GANANCIAS_ / cantidad_prod) %>% 
  collect() %>%
  slice_max(order_by = prom_ganancias, n = 20) 


plot_ly(
  SKU_ganancia_prom,
  y = ~prom_ganancias,
  x = ~reorder(product_name, -prom_ganancias),
  type = "bar",
  name = "Ganancias promedio",
  marker = list(color = "steelblue")
) %>%
  layout(
    title = "Ganancias promedio ($) por producto",
    xaxis = list(title = "Producto",
      tickfont = list(size = 9)),
    yaxis = list(title = "Ganancias promedio")
  ) 
```

#### T√©cnicas estad√≠sticas - Objetivo 2

......

#### Resultados - Objetivo 2

......

## Resultados generales y conclusiones

......

